{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oc4H7ifG-FCI",
    "jukit_cell_id": "pIHQKkr9FK"
   },
   "source": [
    "## Variational AutoEncoders\n",
    "\n",
    "In this lab excercise you will train a Variational AutoEncoder to learn the distribution of the MNIST data. You will explore the latent space and learn how to generate new samples.\n",
    "\n",
    "Some notation:\n",
    "* $P^*$ is the true data distribution. We have some samples from this.\n",
    "* $p(z)$ is a *prior* distribution over the latent space. In our model it is multivariate gaussian distribution $N(0,\\mathbb{I})$.\n",
    "* $E(x)$ is the encoder that accepts data points as input and outputs distributions over the latent space $Z$. The produced distribution is denoted $q_\\phi(z|x)$ and is the (approximate) *posterior* distribution. In our model this is mutlivariate gaussian distribution $q_\\phi(z|x) \\sim N(\\mu, diag(\\sigma^2)$. Notes:\n",
    "    1. $\\phi$ are weights of the encoder network.\n",
    "    2. Encoder network accepts data points as input and outputs $\\mu$ and $\\sigma$, which are vectors of the same length as latent space. They are used to construct the approximate posterior distribution $q_\\phi(z|x)$.\n",
    "* $D(z)$ is the decoder that accepts samples from the latent distribution and output parameters of the the likelihood distribution $p_\\theta(x|z)$. In our model this is Bernoulli trial per each pixel $p_\\theta(x|z_0) \\sim Bern(p)$. Notes:\n",
    "    1. $\\theta$ are weights of the decoder network.\n",
    "    2. Decoder network accepts sample from the posterior distribution $q_\\phi(z|x)$ and outputs p, which is a matrix of the shape of the input image. Each value of the matrix is the parameter $\\pi$ of the Bernoulli trial $Bern(\\pi)$ for the corresponding pixel.\n",
    "    3. Data points are clipped to only contain values 0 and 1 so that the model could be trained in the given setup.\n",
    "\n",
    "Loss:\n",
    "The loss that is used is called ELBO (the Evidence Lower Bound).\n",
    "\n",
    "$$ELBO = \\mathbb{E}_{z \\sim q(z|x)} \\big[\\log p_\\theta(x|z)\\big] - \\mathbb{KL}\\big(q_\\phi(z | x) || p(z)\\big).$$\n",
    "\n",
    "The following equation holds:\n",
    "\n",
    "\n",
    "$$\\log p_{\\theta}(x) = ELBO + \\mathbb{KL}(q_\\theta(z|x) || p(z|x))$$\n",
    "\n",
    "Maximization of ELBO is equivalent of minimization of KL-divergence between to variational posterior distribution and the true posterior distribution.\n",
    "\n",
    "The first term of the loss is trained via stochastic gradient descent. The second term can be calculated analytically in our setup and is equal to:\n",
    "\n",
    "$$ \\mathbb{KL}\\big( \\mathcal{N}(\\mu, \\sigma^2) || \\mathcal{N}(0, 1) \\big) = \\frac12 \\big(\\sigma^2  - \\log(\\sigma^2) + \\mu^2 - 1 \\big).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXUastP5-FCJ",
    "jukit_cell_id": "RtyXwx9fPx"
   },
   "source": [
    "Tasks for the tutorial:\n",
    "1. Run the pipeline and verify that VAE is training and generating decent digit representation.\n",
    "2. Play with training parameters and / or network layers to better learn hidden representation of the data\n",
    "3. Implement sample_latent method in the VariationalAutoEncoder class, which accepts original image as input and outputs samples from the posterior distribution $q_\\phi(z|x)$.\n",
    "4. Implement sample method in the VariationalAutoEncoder class, which accepts sample size and optionally samples from the prior distribution. as input and outputs samples:\n",
    "    1. If samples are not avialable, take a sample $z_0 \\sim p(z)$ from the prior distribution.\n",
    "    2. Decode the latent $p_\\theta(x|z_0) = D_\\theta(z_0)$.\n",
    "    3. Sample a reconstruction from the likelihood: $x_0 \\sim p_\\theta(x|z_0)$.\n",
    "5. Explore the latent space. For each class encode a sample (>=100) of images of that class and take one parameters from the posterior distribution $q_\\phi(z|x)$ per image. Visualize samples as scatter plot. Remember to color points according to image classes!\n",
    "5. Sample two points $z_0, z_1$ from the prior distibution $p(z)$. Perform interpolation i.e. visualize how samples change based on points from segment ended by $z_0$ and $z_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wY7V_y6e-FCJ",
    "jukit_cell_id": "pDhDmcelEe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms # type: ignore\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XefdMpOj-FCJ",
    "jukit_cell_id": "EiwAAcwFio"
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "test_batch_size = 1000\n",
    "epochs = 5\n",
    "lr = 5e-3\n",
    "seed = 1\n",
    "log_interval = 5\n",
    "latent_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R0sfJjEh-FCK",
    "jukit_cell_id": "Z87FGYM0il"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': batch_size}\n",
    "test_kwargs = {'batch_size': test_batch_size}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                    'pin_memory': True,\n",
    "                    'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NZ5G3DxB-FCK",
    "jukit_cell_id": "xrVvSGrkSL"
   },
   "outputs": [],
   "source": [
    "def visualize_data(\n",
    "    images: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    max_images: int,\n",
    "    max_fig_size=(30, 30)\n",
    "):\n",
    "\n",
    "    num_frames, num_channels, h, w, = images.shape\n",
    "    num_frames = min(num_frames, max_images)\n",
    "    ff, axes = plt.subplots(1, num_frames,\n",
    "                            figsize=max_fig_size,\n",
    "                            subplot_kw={'xticks': [], 'yticks': []})\n",
    "    if num_frames == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i in range(0, num_frames):\n",
    "        if num_channels == 3:\n",
    "            axes[i].imshow(np.squeeze(images[i]))\n",
    "        else:\n",
    "            axes[i].imshow(np.squeeze(images[i]), cmap='gray')\n",
    "        if labels is not None:\n",
    "            axes[i].set_title(labels[i].item(), fontsize=28)\n",
    "        plt.setp(axes[i].get_xticklabels(), visible=False)\n",
    "        plt.setp(axes[i].get_yticklabels(), visible=False)\n",
    "    ff.subplots_adjust(wspace=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YymQPDD5-FCK",
    "jukit_cell_id": "ZR40BQxeGP"
   },
   "outputs": [],
   "source": [
    "class Binarize:\n",
    "    def __call__(self, sample: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.bernoulli(sample)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Binarize()\n",
    "])\n",
    "\n",
    "dataset1 = datasets.MNIST('./data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('./data', train=False,\n",
    "                    transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Eb_G_gyc-FCK",
    "jukit_cell_id": "D3EMM5HuMy"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x3000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "real_batch = next(iter(train_loader))\n",
    "visualize_data(real_batch[0], real_batch[1], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "V5uJu6vj-FCK",
    "jukit_cell_id": "lDWaCw7ncK"
   },
   "outputs": [],
   "source": [
    "EncoderOutput = namedtuple(\"EncoderOutput\", [\"mu\", \"sigma\"])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        linear_sizes: list[int],\n",
    "        latent_size: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for in_layer_size, out_layer_size in zip(linear_sizes, linear_sizes[1:]):\n",
    "            self.layers.append(nn.Linear(in_layer_size, out_layer_size))\n",
    "            self.layers.append(nn.BatchNorm1d(out_layer_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "\n",
    "        self.last_layer_mu = nn.Linear(linear_sizes[-1], latent_size)\n",
    "        self.last_layer_sigma = nn.Linear(linear_sizes[-1], latent_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = nn.Flatten()(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        mu = self.last_layer_mu(x)\n",
    "        logsigma = self.last_layer_sigma(x)\n",
    "        return EncoderOutput(mu, torch.log(1 + torch.exp(logsigma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lfsCDhcQ-FCK",
    "jukit_cell_id": "gOtr8l8qF4"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        linear_sizes: list[int],\n",
    "        output_size: tuple[int]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for in_layer_size, out_layer_size in zip(linear_sizes, linear_sizes[1:]):\n",
    "            self.layers.append(nn.Linear(in_layer_size, out_layer_size))\n",
    "            self.layers.append(nn.BatchNorm1d(out_layer_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "\n",
    "        self.last_layer = nn.Sequential(\n",
    "            nn.Linear(linear_sizes[-1], output_size[0] * output_size[1]),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        for layer in self.layers:\n",
    "            z = layer(z)\n",
    "\n",
    "        x = self.last_layer(z)\n",
    "\n",
    "        x = x.view(-1, 1, *self.output_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aaESKiTG-FCL",
    "jukit_cell_id": "bhd31Y9iWU"
   },
   "outputs": [],
   "source": [
    "VariationalAutoEncoderOutput = namedtuple(\"VariationalAutoEncoderOutput\", [\"mu\", \"sigma\", \"p\"])\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_linear_sizes: list[int],\n",
    "        latent_size: int,\n",
    "        decoder_linear_sizes: list[int],\n",
    "        output_size: tuple[int]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(encoder_linear_sizes, latent_size)\n",
    "        self.decoder = Decoder(decoder_linear_sizes, output_size)\n",
    "        self.latent_size = latent_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        z = torch.normal(0., 1., size=list(encoded.mu.size())).to(device)\n",
    "        z = (z * encoded.sigma) + encoded.mu\n",
    "\n",
    "        decoded = self.decoder(z)\n",
    "        return VariationalAutoEncoderOutput(encoded.mu, encoded.sigma, decoded)\n",
    "\n",
    "    def sample_latent(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # TODO: Task 3.\n",
    "        pass\n",
    "\n",
    "    def sample(self, sample_size: int, samples=None) -> torch.Tensor:\n",
    "        # TODO: Task 4.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4_r1lpXa-FCL",
    "jukit_cell_id": "lvLfQuqbgf"
   },
   "outputs": [],
   "source": [
    "def KL_gaussian_loss(mu, sigma):\n",
    "    return torch.mean(((sigma * sigma) - (2 * torch.log(sigma)) + (mu * mu) - 1) / 2)\n",
    "\n",
    "def ELBO(x, p, mu, sigma):\n",
    "    BCE = F.binary_cross_entropy(p, x)\n",
    "    KL = KL_gaussian_loss(mu, sigma)\n",
    "    return BCE + KL * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Zk9JPfZX-FCL",
    "jukit_cell_id": "yDxpIMfrnA"
   },
   "outputs": [],
   "source": [
    "def train(model: nn.Module, device: torch.device, train_loader: DataLoader,\n",
    "          optimizer: optim.Optimizer, epoch: int, log_interval: int):\n",
    "    model.train()\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = ELBO(data, output.p, output.mu, output.sigma)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model: nn.Module, device: torch.device, test_loader: DataLoader):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            loss = ELBO(data, output.p, output.mu, output.sigma)\n",
    "            test_loss = test_loss + (loss * data.size(0))\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "m-WSVyBv-FCL",
    "jukit_cell_id": "8z8DaWFxZw"
   },
   "outputs": [],
   "source": [
    "vae = VariationalAutoEncoder([28 * 28, 500, 350], latent_size, [latent_size, 350, 500], (28, 28))\n",
    "vae.to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "and-7B8q-FCM",
    "jukit_cell_id": "0EgbJq8zsj"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train(vae, device, \u001b[43mtrain_loader\u001b[49m, optimizer, epoch, log_interval)\n\u001b[1;32m      3\u001b[0m     test(vae, device, test_loader)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(vae, device, train_loader, optimizer, epoch, log_interval)\n",
    "    test(vae, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1644Gbj-FCM",
    "jukit_cell_id": "GZhv2SnWvs"
   },
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "visualize_data(\n",
    "    vae(real_batch[0].to(device)).p.detach().cpu().numpy(),\n",
    "    labels=real_batch[1].cpu().numpy(),\n",
    "    max_images=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14ZTUm0P-FCM",
    "jukit_cell_id": "zR2QvB46U2"
   },
   "outputs": [],
   "source": [
    "visualize_data(\n",
    "    torch.bernoulli(vae(real_batch[0].to(device)).p).detach().cpu().numpy(),\n",
    "    labels=real_batch[1].cpu().numpy(),\n",
    "    max_images=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSZ7dwSN-FCM",
    "jukit_cell_id": "3u0aaKb096"
   },
   "source": [
    "Visualization of latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "t_MRrHCj-FCM",
    "jukit_cell_id": "ac2sV6BoJf"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Task 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta0YPwc5-FCM",
    "jukit_cell_id": "GpGpgLNLS6"
   },
   "source": [
    "Sample interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xzC_7MUS-FCM",
    "jukit_cell_id": "oy0iwiaUEv"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "# TODO\n",
    "# Task 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMyu71gY-FCM",
    "jukit_cell_id": "EwZ5GE7s8b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
