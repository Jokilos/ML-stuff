{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcTwzhX8fBqs"
   },
   "source": [
    "Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "This exercise covers two aspects:\n",
    "* In tasks 1-6 you will implement mechanisms that allow training deeper models (better initialization, batch normalization). Note that for dropout and batch norm you are expected to implement it yourself without relying on ready-made components from Pytorch. After doing each of the tasks you can look at the plots and check how your changes impact gradients of network layers.\n",
    "* In task 7 you will implement a convnet using [conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
    "\n",
    "\n",
    "Tasks:\n",
    "1. Check that the given implementation reaches 95% test accuracy for\n",
    "   architecture input-64-64-10 in a few thousand batches.\n",
    "2. Improve initialization and check that the network learns much faster\n",
    "   and reaches over 97% test accuracy. A good basic initialization scheme is so-called Glorot initialization. For a set of weights going from a layer with $n_{in}$ neurons to a layer with $n_{out}$ neurons, it samples each weight from normal distribution with $0$ mean and standard deviation of $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$.  \n",
    "Check how better initialization changes distribution of gradients at the first epoch.\n",
    "3. Check, that with proper initialization we can train architecture\n",
    "   input-64-64-64-64-64-10, while with bad initialization it does\n",
    "   not even get off the ground.\n",
    "4. Add dropout implemented in pytorch (but without using torch.nn.Dropout)\n",
    "5. Check that with 10 hidden layers (64 units each) even with proper\n",
    "    initialization the network has a hard time to start learning.\n",
    "6. Implement batch normalization (use train mode also for testing - it should perform well enough):\n",
    "    * compute batch mean and variance\n",
    "    * add new variables beta and gamma\n",
    "    * check that the networks learns much faster for 5 layers\n",
    "    * check that the network learns even for 10 hidden layers.\n",
    "    * check how gradients change in comparison to network without batch norm.\n",
    "7. So far we worked with a fully connected network. Design and implement in pytorch (by using pytorch functions) a simple convolutional network and achieve 99% test accuracy. The architecture is up to you, but even a few convolutional layers should be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "IYAsziKffBFV"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cellView": "form",
    "collapsed": true,
    "id": "D2cTAah4oMkJ"
   },
   "outputs": [],
   "source": [
    "#@title Visualize gradients\n",
    "\n",
    "class GradientVisualizer:\n",
    "    def __init__(self, net, num_epochs):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.linear_layers = self.get_linear_layers(net)\n",
    "\n",
    "        self.grad_to_weight_fig = None\n",
    "        self.grads_in_layers_fig = None\n",
    "        self.grads_at_epochs_fig = None\n",
    "        self.init_figures()\n",
    "\n",
    "    def get_linear_layers(self, net):\n",
    "        linear_layers = []\n",
    "        for field in net.__dict__['_modules'].values():\n",
    "            if isinstance(field, Linear):\n",
    "                linear_layers.append(field)\n",
    "            if isinstance(field, nn.ModuleList):\n",
    "                for module in field:\n",
    "                    if isinstance(module, Linear):\n",
    "                        linear_layers.append(module)\n",
    "\n",
    "        assert linear_layers, \\\n",
    "        ('No linear layers found. Linear layers should be parameters of the network or they '\n",
    "        'should be placed in a ModuleList which is a parameter of the network.')\n",
    "        return linear_layers\n",
    "\n",
    "    def get_epochs_for_one_layer(self):\n",
    "        \"\"\"\n",
    "        We want to show gradient distributions from up to 7 selected epochs\n",
    "        for one linear layer.\n",
    "        \"\"\"\n",
    "        if self.num_epochs < 7:\n",
    "            return list(range(self.num_epochs))\n",
    "        else:\n",
    "            return torch.linspace(0, self.num_epochs - 1, 7).int().tolist()\n",
    "\n",
    "    def get_three_epochs(self):\n",
    "        \"\"\"\n",
    "        We want to show gradients distributions from all layers at each of\n",
    "        three epochs: first, middle and last.\n",
    "        \"\"\"\n",
    "        return [0, self.num_epochs // 2, self.num_epochs - 1]\n",
    "\n",
    "    def rgb_to_rgba(self, rgb_color, epoch):\n",
    "        \"\"\"\n",
    "        Value of epoch parameter determines how transparent color should be\n",
    "        in comparison to others.\n",
    "        Colors for earlier epochs should be more transparent/less visible.\n",
    "        \"\"\"\n",
    "        return f'rgba{rgb_color[3:-1]},{0.6 * (epoch + 1) / self.num_epochs + 0.15})'\n",
    "\n",
    "    def init_figures(self):\n",
    "        # Initialize figure with gradient to weight ratio plot\n",
    "        fig = go.Figure()\n",
    "        fig.update_layout(\n",
    "            title='Gradient standard deviation to weight standard deviation ratio', title_x=0.5,\n",
    "            xaxis_title='Epoch',\n",
    "            yaxis_title='Gradient to weight ratio (log scale)',\n",
    "            height=400, width=1500, margin=dict(b=10, t=60)\n",
    "        )\n",
    "        fig.update_yaxes(type='log')\n",
    "        for i in range(len(self.linear_layers)):\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[], y=[],\n",
    "                mode='lines+markers', name=f'Linear layer {i}'\n",
    "            ))\n",
    "\n",
    "        self.grad_to_weight_fig = go.FigureWidget(fig)\n",
    "        display(self.grad_to_weight_fig)\n",
    "\n",
    "        # Initialize figure visualizing gradient distributions in layers\n",
    "        num_rows = (len(self.linear_layers) - 1) // 3 + 1\n",
    "        fig = make_subplots(\n",
    "            rows=num_rows, cols=3,\n",
    "            subplot_titles=[f'Linear layer {i}' for i in range(len(self.linear_layers))],\n",
    "            vertical_spacing=0.2 / num_rows\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            title='Comparison between epochs of gradient distributions in layers', title_x=0.5,\n",
    "            height=num_rows * 400, width=1500, margin=dict(b=10, t=60)\n",
    "        )\n",
    "\n",
    "        colors, _ = px.colors.convert_colors_to_same_type(2 * px.colors.qualitative.Plotly)\n",
    "        for layer_num in range(len(self.linear_layers)):\n",
    "            row = layer_num // 3 + 1\n",
    "            col = layer_num % 3 + 1\n",
    "            fig.update_xaxes(\n",
    "                title_text='Gradient value', range=(-0.1, 0.1), row=row, col=col\n",
    "            )\n",
    "            fig.update_yaxes(\n",
    "                title_text='Density (log scale)', type='log', row=row, col=col\n",
    "            )\n",
    "\n",
    "            # Create empty traces and update them later with actual gradient distributions.\n",
    "            # Unfortunately, we cannot add new traces dynamically because Colab has problem\n",
    "            # with widgets from plotly (traces added dynamically are rendered twice).\n",
    "            for epoch in self.get_epochs_for_one_layer():\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        mode='lines', name=f'Epoch {epoch + 1}',\n",
    "                        line=dict(color=self.rgb_to_rgba(colors[layer_num], epoch)),\n",
    "                        legendgroup=layer_num\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "\n",
    "        self.grads_in_layers_fig = go.FigureWidget(fig)\n",
    "        display(self.grads_in_layers_fig)\n",
    "\n",
    "        # Initialize figure comparing gradient distributions between layers at the\n",
    "        # first, middle and last epoch\n",
    "        selected_epochs_indices = self.get_three_epochs()\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=3,\n",
    "            subplot_titles=[f'Epoch {epoch + 1}' for epoch in selected_epochs_indices]\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            title='Comparison between layers of gradient distributions at epochs', title_x=0.5,\n",
    "            height=400, width=1500, margin=dict(b=10, t=60)\n",
    "        )\n",
    "\n",
    "        for col, epoch in enumerate(selected_epochs_indices, 1):\n",
    "            fig.update_yaxes(title_text='Density (log scale)', type='log', row=1, col=col)\n",
    "            fig.update_xaxes(\n",
    "                title_text='Gradient value',\n",
    "                range=(-0.05, 0.05) if epoch != 0 else (-1, 1),\n",
    "                row=1, col=col\n",
    "            )\n",
    "\n",
    "            # Create empty traces and update them later with actual gradient distributions.\n",
    "            for layer_num in range(len(self.linear_layers)):\n",
    "                fig.append_trace(\n",
    "                    go.Scatter(\n",
    "                        mode='lines', name=f'Linear layer {layer_num}',\n",
    "                        line=dict(color=colors[layer_num]), showlegend=(col == 1)\n",
    "                    ),\n",
    "                    row=1, col=col\n",
    "                )\n",
    "\n",
    "        self.grads_at_epochs_fig = go.FigureWidget(fig)\n",
    "        display(self.grads_at_epochs_fig)\n",
    "\n",
    "    def visualize_gradients(self, lr, epoch, batch_idx):\n",
    "        # It is enough to use gradients calculated for the first batch.\n",
    "        if batch_idx != 0:\n",
    "            return\n",
    "\n",
    "        epoch_grads = []\n",
    "        epoch_grad_to_weight_ratios = []\n",
    "        for layer in self.linear_layers:\n",
    "            epoch_grads.append(layer.weight.grad.flatten().detach())\n",
    "            epoch_grad_to_weight_ratios.append(\n",
    "                (lr * layer.weight.grad.std() / layer.weight.std()).item()\n",
    "            )\n",
    "\n",
    "        # Update figure with gradient to weight ratio plot\n",
    "        for i, grad_to_weight_ratio in enumerate(epoch_grad_to_weight_ratios):\n",
    "            x = self.grad_to_weight_fig.data[i].x\n",
    "            next_x_val = x[-1] + 1 if x else 1\n",
    "            self.grad_to_weight_fig.data[i].x += (next_x_val, )\n",
    "            self.grad_to_weight_fig.data[i].y += (grad_to_weight_ratio, )\n",
    "\n",
    "        # Update figure visualizing gradient distributions in layers\n",
    "        selected_epochs = self.get_epochs_for_one_layer()\n",
    "        if epoch in selected_epochs:\n",
    "            epoch_idx = selected_epochs.index(epoch)\n",
    "            for layer_num, layer_grad in enumerate(epoch_grads):\n",
    "                trace_idx = layer_num * len(selected_epochs) + epoch_idx\n",
    "                hy, hx = torch.histogram(layer_grad, bins=50, density=True)\n",
    "                hy = hy / max(hy) + 0.001\n",
    "                self.grads_in_layers_fig.data[trace_idx].x = hx[:-1].tolist()\n",
    "                self.grads_in_layers_fig.data[trace_idx].y = hy.tolist()\n",
    "\n",
    "        # Update figure visualizing gradient distributions at epochs\n",
    "        selected_epochs = self.get_three_epochs()\n",
    "        if epoch in selected_epochs:\n",
    "            epoch_idx = selected_epochs.index(epoch)\n",
    "            for layer_num, layer_grad in enumerate(epoch_grads):\n",
    "                trace_idx = epoch_idx * len(self.linear_layers) + layer_num\n",
    "                hy, hx = torch.histogram(layer_grad, bins=50, density=True)\n",
    "                hy = hy / max(hy) + 0.001\n",
    "                self.grads_at_epochs_fig.data[trace_idx].x = hx[:-1].tolist()\n",
    "                self.grads_at_epochs_fig.data[trace_idx].y = hy.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "DMtap4QCfBH8"
   },
   "outputs": [],
   "source": [
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, glorot=False, batch_norm=False, eps=1e-6):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.gamma = Parameter(torch.Tensor(in_features))\n",
    "        self.beta = Parameter(torch.Tensor(in_features))\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = Parameter(torch.Tensor(out_features))\n",
    "        self.eps = eps\n",
    "        self.glorot = glorot\n",
    "        self.bn = batch_norm\n",
    "        self.reset_glorot()\n",
    "\n",
    "    def reset_glorot(self):\n",
    "        if self.glorot:\n",
    "            stddev = (2 / (self.in_features + self.out_features)) ** (1/2)\n",
    "        else:\n",
    "            stddev = 0.25\n",
    "\n",
    "        self.weight.data.normal_(mean = 0, std = stddev)\n",
    "        init.zeros_(self.beta)\n",
    "        init.zeros_(self.bias)\n",
    "        init.ones_(self.gamma)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.bn:\n",
    "            batch_size, _ = x.shape \n",
    "        \n",
    "            means = (1 / batch_size) * torch.sum(x, dim = 0)\n",
    "            means = means.repeat(batch_size, 1)\n",
    "            variances = (1 / batch_size) * torch.sum((x - means)**2, dim = 0)\n",
    "            variances = variances.repeat(batch_size, 1)\n",
    "\n",
    "            numerator = x - means\n",
    "            denominator = (variances + self.eps)**(1/2)\n",
    "            x = self.gamma * (numerator / denominator) + self.beta\n",
    "\n",
    "            return x.matmul(self.weight.t())\n",
    "        else:\n",
    "            return x.matmul(self.weight.t()) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(torch.nn.Module):\n",
    "    def __init__(self, features, p=0.95):\n",
    "        super(Dropout, self).__init__()\n",
    "        self.features = features\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        dropout = torch.Tensor(x.shape)\n",
    "        dropout.bernoulli_(p = self.p)\n",
    "        new_x = x * dropout\n",
    "\n",
    "        return new_x * (1/self.p)\n",
    "    \n",
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, sizes, glorot=False, dropout=False, batch_norm=False):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        dropouts = [Dropout(s) for s in sizes[1:-1]] + [Identity()]\n",
    "        sizes = np.array(sizes)\n",
    "        sizes2 = np.vstack([sizes[:-1], sizes[1:]]).T\n",
    "        modules = [Linear(*s, glorot=glorot, batch_norm=batch_norm) for s in sizes2]\n",
    "\n",
    "        self.fcs = nn.ModuleList(modules)\n",
    "        self.dps = nn.ModuleList(dropouts)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        activasion_funs = [F.relu] * (len(self.fcs) - 1) + [lambda x : x]\n",
    "\n",
    "        x = x.view(-1, 28 * 28)\n",
    "\n",
    "        tuple_list = zip(self.fcs, self.dps, activasion_funs)\n",
    "\n",
    "        for fc, dp, activation_fun in tuple_list:\n",
    "            x = activation_fun(fc(x))\n",
    "\n",
    "            if self.dropout:\n",
    "                x = dp(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DropoutNet, self).__init__()\n",
    "        self.fc1 = Linear(784, 64)\n",
    "        self.dp1 = Dropout(64)\n",
    "        self.fc2 = Linear(64, 64)\n",
    "        self.dp2 = Dropout(64)\n",
    "        self.fc3 = Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dp1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class BatchNormNet(nn.Module):\n",
    "    def __init__(self, dropout=False):\n",
    "        super(BatchNormNet, self).__init__()\n",
    "        self.fc1 = Linear(784, 64, True)\n",
    "        self.dp1 = Dropout(64) if dropout else Identity()\n",
    "        self.fc2 = Linear(64, 64, True)\n",
    "        self.dp2 = Dropout(64) if dropout else Identity()\n",
    "        self.fc3 = Linear(64, 10, True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dp1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "WgfUP23AfBMd"
   },
   "outputs": [],
   "source": [
    "class MnistTrainer(object):\n",
    "    def __init__(self, batch_size):\n",
    "        transform = transforms.Compose(\n",
    "                [transforms.ToTensor()])\n",
    "        self.trainset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            download=True,\n",
    "            train=True,\n",
    "            transform=transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(\n",
    "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "        self.testset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True, transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(\n",
    "            self.testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    def train(self, net, gradient_visualizer, epochs=20, lr=0.05, momentum=0.9):\n",
    "        gv = gradient_visualizer is not None\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.trainloader):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                if gv:\n",
    "                    gradient_visualizer.visualize_gradients(lr, epoch, i)\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in self.testloader:\n",
    "                    images, labels = data\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "                total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "wO3ooSNUHiQz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "epochs = 10\n",
    "\n",
    "# no glorot - crashes on 7\n",
    "# with glorot - sometimes crashes on ~15\n",
    "# glorot + batchnorm - easily trains on 19\n",
    "# cannot test highet bcs of some bug in gradient visualizer ;(\n",
    "hidden_layers = 19\n",
    "net = Net([784] + [64] * hidden_layers + [10], glorot = True, dropout = False, batch_norm = True)\n",
    "gradient_visualizer = GradientVisualizer(net, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.235\n",
      "[1,   200] loss: 0.228\n",
      "[1,   300] loss: 0.235\n",
      "[1,   400] loss: 0.233\n",
      "Accuracy of the network on the 10000 test images: 92.85 %\n",
      "[2,   100] loss: 0.210\n",
      "[2,   200] loss: 0.219\n",
      "[2,   300] loss: 0.214\n",
      "[2,   400] loss: 0.216\n",
      "Accuracy of the network on the 10000 test images: 93.51 %\n",
      "[3,   100] loss: 0.185\n",
      "[3,   200] loss: 0.190\n",
      "[3,   300] loss: 0.195\n",
      "[3,   400] loss: 0.194\n",
      "Accuracy of the network on the 10000 test images: 93.61 %\n",
      "[4,   100] loss: 0.184\n",
      "[4,   200] loss: 0.177\n",
      "[4,   300] loss: 0.180\n",
      "[4,   400] loss: 0.180\n",
      "Accuracy of the network on the 10000 test images: 94.14 %\n",
      "[5,   100] loss: 0.158\n",
      "[5,   200] loss: 0.157\n",
      "[5,   300] loss: 0.175\n",
      "[5,   400] loss: 0.163\n",
      "Accuracy of the network on the 10000 test images: 94.01 %\n",
      "[6,   100] loss: 0.155\n",
      "[6,   200] loss: 0.153\n",
      "[6,   300] loss: 0.136\n",
      "[6,   400] loss: 0.160\n",
      "Accuracy of the network on the 10000 test images: 94.23 %\n",
      "[7,   100] loss: 0.141\n",
      "[7,   200] loss: 0.138\n",
      "[7,   300] loss: 0.140\n",
      "[7,   400] loss: 0.138\n",
      "Accuracy of the network on the 10000 test images: 94.34 %\n",
      "[8,   100] loss: 0.137\n",
      "[8,   200] loss: 0.135\n",
      "[8,   300] loss: 0.148\n",
      "[8,   400] loss: 0.129\n",
      "Accuracy of the network on the 10000 test images: 94.6 %\n",
      "[9,   100] loss: 0.116\n",
      "[9,   200] loss: 0.125\n",
      "[9,   300] loss: 0.125\n",
      "[9,   400] loss: 0.129\n",
      "Accuracy of the network on the 10000 test images: 94.32 %\n",
      "[10,   100] loss: 0.121\n",
      "[10,   200] loss: 0.113\n",
      "[10,   300] loss: 0.124\n",
      "[10,   400] loss: 0.132\n",
      "Accuracy of the network on the 10000 test images: 94.52 %\n"
     ]
    }
   ],
   "source": [
    "trainer = MnistTrainer(batch_size=128)\n",
    "trainer.train(net, gradient_visualizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.609\n",
      "[1,   200] loss: 0.212\n",
      "[1,   300] loss: 0.132\n",
      "[1,   400] loss: 0.109\n",
      "Accuracy of the network on the 10000 test images: 97.2 %\n",
      "[2,   100] loss: 0.088\n",
      "[2,   200] loss: 0.077\n",
      "[2,   300] loss: 0.074\n",
      "[2,   400] loss: 0.076\n",
      "Accuracy of the network on the 10000 test images: 98.12 %\n",
      "[3,   100] loss: 0.054\n",
      "[3,   200] loss: 0.052\n",
      "[3,   300] loss: 0.048\n",
      "[3,   400] loss: 0.057\n",
      "Accuracy of the network on the 10000 test images: 97.96 %\n",
      "[4,   100] loss: 0.046\n",
      "[4,   200] loss: 0.048\n",
      "[4,   300] loss: 0.042\n",
      "[4,   400] loss: 0.041\n",
      "Accuracy of the network on the 10000 test images: 98.38 %\n",
      "[5,   100] loss: 0.036\n",
      "[5,   200] loss: 0.032\n",
      "[5,   300] loss: 0.040\n",
      "[5,   400] loss: 0.038\n",
      "Accuracy of the network on the 10000 test images: 98.14 %\n",
      "[6,   100] loss: 0.030\n",
      "[6,   200] loss: 0.027\n",
      "[6,   300] loss: 0.037\n",
      "[6,   400] loss: 0.040\n",
      "Accuracy of the network on the 10000 test images: 98.52 %\n",
      "[7,   100] loss: 0.027\n",
      "[7,   200] loss: 0.028\n",
      "[7,   300] loss: 0.029\n",
      "[7,   400] loss: 0.029\n",
      "Accuracy of the network on the 10000 test images: 98.8 %\n",
      "[8,   100] loss: 0.025\n",
      "[8,   200] loss: 0.022\n",
      "[8,   300] loss: 0.020\n",
      "[8,   400] loss: 0.027\n",
      "Accuracy of the network on the 10000 test images: 98.69 %\n",
      "[9,   100] loss: 0.021\n",
      "[9,   200] loss: 0.020\n",
      "[9,   300] loss: 0.016\n",
      "[9,   400] loss: 0.021\n",
      "Accuracy of the network on the 10000 test images: 98.99 %\n",
      "[10,   100] loss: 0.016\n",
      "[10,   200] loss: 0.019\n",
      "[10,   300] loss: 0.019\n",
      "[10,   400] loss: 0.030\n",
      "Accuracy of the network on the 10000 test images: 98.74 %\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "net = ConvolutionalNet()\n",
    "trainer = MnistTrainer(batch_size=128)\n",
    "trainer.train(net, None, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
