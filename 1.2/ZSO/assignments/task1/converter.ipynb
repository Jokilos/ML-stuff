{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "import capstone\n",
    "import keystone\n",
    "import shutil\n",
    "import struct\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_idx_dict(names):\n",
    "    d = {} \n",
    "    for i, n in enumerate(names):\n",
    "        d[n] = i\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Const:\n",
    "    HEADER_SIZE = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElfHeader:\n",
    "    unpacked_data = None\n",
    "\n",
    "    fields = [\n",
    "        \"e_ident\",\n",
    "        \"e_type\",\n",
    "        \"e_machine\",\n",
    "        \"e_version\",\n",
    "        \"e_entry\",\n",
    "        \"e_phoff\",\n",
    "        \"e_shoff\",\n",
    "        \"e_flags\",\n",
    "        \"e_ehsize\",\n",
    "        \"e_phentsize\",\n",
    "        \"e_phnum\",\n",
    "        \"e_shentsize\",\n",
    "        \"e_shnum\",\n",
    "        \"e_shstrndx\",\n",
    "    ]\n",
    "\n",
    "    idx_dict = make_idx_dict(fields)\n",
    "\n",
    "    format = (\n",
    "        # e_ident (16 bytes), e_type (2 bytes), e_machine (2 bytes), e_version (4 bytes)\n",
    "        '< 16s H H I' +\n",
    "        # e_entry (8 bytes), e_phoff (8 bytes), e_shoff (8 bytes), e_flags (4 bytes)\n",
    "        'Q Q Q I' +\n",
    "        # e_ehsize (2 bytes), e_phentsize (2 bytes), e_phnum (2 bytes), e_shentsize (2 bytes)\n",
    "        'H H H H' +\n",
    "        # e_shnum (2 bytes), e_shstrndx (2 bytes)\n",
    "        'H H'\n",
    "    )\n",
    "\n",
    "    def print():\n",
    "        for i, f in enumerate(ElfHeader.fields):\n",
    "            print(f'{f}: {ElfHeader.unpacked_data[i]}')\n",
    "    \n",
    "    def read_elf_header():\n",
    "        if ElfFile.data[:4] != b'\\x7fELF':\n",
    "            raise ValueError(\"Not a valid ELF file.\")\n",
    "        \n",
    "        ElfHeader.unpacked_data = list(struct.unpack(ElfHeader.format, ElfFile.data[:Const.HEADER_SIZE]))\n",
    "\n",
    "    def overwrite_elf_header(file_path):\n",
    "        amd_machine = 0x003e\n",
    "        ElfHeader.unpacked_data[2] = amd_machine\n",
    "\n",
    "        packed_data = struct.pack(ElfHeader.format, *ElfHeader.unpacked_data)\n",
    "\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(packed_data)\n",
    "            f.write(ElfFile.data[Const.HEADER_SIZE:])\n",
    "\n",
    "    def get(name):\n",
    "        idx = ElfHeader.idx_dict[name]\n",
    "        return ElfHeader.unpacked_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SectionHeader:\n",
    "    fields = [\n",
    "        \"sh_name\",      # Section name (index into section header string table)\n",
    "        \"sh_type\",      # Section type\n",
    "        \"sh_flags\",     # Section attributes\n",
    "        \"sh_addr\",      # Virtual address in memory\n",
    "        \"sh_offset\",    # Offset in file\n",
    "        \"sh_size\",      # Size of section\n",
    "        \"sh_link\",      # Link to other section\n",
    "        \"sh_info\",      # Miscellaneous information\n",
    "        \"sh_addralign\", # Address alignment boundary\n",
    "        \"sh_entsize\"    # Size of entries, if section has table\n",
    "    ]\n",
    "\n",
    "    format = (\n",
    "        # sh_name (4 bytes), sh_type (4 bytes), sh_flags (8 bytes), sh_addr (8 bytes)\n",
    "        '< I I Q Q' +  \n",
    "        # sh_offset (8 bytes), sh_size (8 bytes), sh_link (4 bytes), sh_info (4 bytes)\n",
    "        'Q Q I I' +    \n",
    "        # sh_addralign (8 bytes), sh_entsize (8 bytes)\n",
    "        'Q Q' \n",
    "    )\n",
    "\n",
    "    idx_dict = make_idx_dict(fields)\n",
    "\n",
    "    shstroff = None\n",
    "    \n",
    "    def __init__(self, offset):\n",
    "        self.unpacked_data = list(\n",
    "            struct.unpack(\n",
    "                SectionHeader.format, \n",
    "                ElfFile.data[offset : offset + ElfHeader.get('e_shentsize')],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        sh_off = self.get('sh_offset')\n",
    "        self.section_data = ElfFile.data[sh_off : sh_off + self.get('sh_size')]\n",
    "\n",
    "        self.name = None\n",
    "\n",
    "    def print(self):\n",
    "        for i, f in enumerate(SectionHeader.fields):\n",
    "            print(f'{f}: {self.data[i]}')\n",
    "\n",
    "    def get(self, name):\n",
    "        idx = SectionHeader.idx_dict[name]\n",
    "        return self.unpacked_data[idx]\n",
    "    \n",
    "    def set_name(self, verbose = False):\n",
    "        self.name = ElfFile.find_string(self.get('sh_name'))\n",
    "\n",
    "        if verbose:\n",
    "            print(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rela:\n",
    "    size = 0x18\n",
    "\n",
    "    format = '<QQq'  # r_offset, r_info, r_addend\n",
    "\n",
    "    fields = ['r_offset', 'r_info', 'r_addend']\n",
    "\n",
    "    idx_dict = make_idx_dict(fields)\n",
    "\n",
    "    #define ELF64_R_SYM(i)((i) >> 32)\n",
    "    def R_SYM(i):\n",
    "        return i >> 32\n",
    "    \n",
    "    #define ELF64_R_TYPE(i)((i) & 0xf f f f f f f f L)\n",
    "    def R_TYPE(i):\n",
    "        return i & 0xffffffff\n",
    "\n",
    "    #define ELF64_R_INFO(s, t)(((s) << 32) + ((t) & 0xf f f f f f f f L))\n",
    "    def R_INFO(s, t):\n",
    "        return s << 32 + t & 0xffffffff\n",
    "\n",
    "    def __init__(self, offset):\n",
    "        self.unpacked_data = struct.unpack(Rela.format, ElfFile.data[offset : offset + Rela.size])\n",
    "        self.offset = offset\n",
    "        info = self.get('r_info')\n",
    "        self.sym = Rela.R_SYM(info)\n",
    "        self.type = Rela.R_TYPE(info)\n",
    "\n",
    "    def print(self):\n",
    "        for i, f in enumerate(Rela.fields):\n",
    "            print(f'{f}: {self.unpacked_data[i]}')\n",
    "\n",
    "        print(f'{self.sym=}')\n",
    "        print(f'{self.type=}')\n",
    "\n",
    "    def overwrite_rela(self, offset):\n",
    "        pass\n",
    "\n",
    "    def get(self, name):\n",
    "        idx = Rela.idx_dict[name]\n",
    "        return self.unpacked_data[idx]\n",
    "\n",
    "    def collect_rela_entries(sh):\n",
    "        base_offset = offset = sh.get('sh_offset')\n",
    "        size = sh.get('sh_size')\n",
    "        entsize = sh.get('sh_entsize')\n",
    "        rela_entries = []\n",
    "\n",
    "        while offset < base_offset + size:\n",
    "            rela_entries += [Rela(offset)]\n",
    "            offset += entsize\n",
    "\n",
    "        return rela_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sym:\n",
    "    size = 0x18\n",
    "\n",
    "    format = (\n",
    "        # st_name(4 bytes), st_info(1 byte), st_other(1 byte)\n",
    "        '< I B B' +\n",
    "        # st_shndx(2 bytes), st_value(8 bytes), st_size(8 bytes)\n",
    "        'H Q Q'\n",
    "    )\n",
    "\n",
    "    fields = [\n",
    "        'st_name',\n",
    "        'st_info',\n",
    "        'st_other',\n",
    "        'st_shndx',\n",
    "        'st_value',\n",
    "        'st_size',\n",
    "    ]\n",
    "\n",
    "    idx_dict = make_idx_dict(fields)\n",
    "\n",
    "    def __init__(self, offset, verbose = False):\n",
    "        self.unpacked_data = struct.unpack(Sym.format, ElfFile.data[offset : offset + Sym.size])\n",
    "        self.offset = offset\n",
    "\n",
    "        self.name = ElfFile.find_string(self.get('sh_name'))\n",
    "\n",
    "        if(verbose):\n",
    "            print(self.name)\n",
    "\n",
    "    def print(self):\n",
    "        for i, f in enumerate(Sym.fields):\n",
    "            print(f'{f}: {self.unpacked_data[i]}')\n",
    "\n",
    "    def overwrite_sym(self, offset):\n",
    "        pass\n",
    "\n",
    "    def get(self, name):\n",
    "        idx = Sym.idx_dict[name]\n",
    "        return self.unpacked_data[idx]\n",
    "\n",
    "    def collect_sym_entries(sh):\n",
    "        base_offset = offset = sh.get('sh_offset')\n",
    "        size = sh.get('sh_size')\n",
    "        entsize = sh.get('sh_entsize')\n",
    "        sym_entries = []\n",
    "\n",
    "        while offset < base_offset + size:\n",
    "            sym_entries += [Sym(offset)]\n",
    "            offset += entsize\n",
    "\n",
    "        return sym_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'axxxxxxde'"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'abcde'\n",
    "x = x[:1] + 'xxxxxx' + x[3:]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:74: SyntaxWarning: 'bool' object is not callable; perhaps you missed a comma?\n",
      "<>:74: SyntaxWarning: 'bool' object is not callable; perhaps you missed a comma?\n",
      "/tmp/ipykernel_5009/3301029149.py:74: SyntaxWarning: 'bool' object is not callable; perhaps you missed a comma?\n",
      "  assert  False \\\n"
     ]
    }
   ],
   "source": [
    "class Comparator:\n",
    "    # for capstone output\n",
    "    hex_pattern = '0x[0-9a-f]+' \n",
    "\n",
    "    prolog = \"\"\"\n",
    "        stp x29, x30, [sp, #-prologue_shift]!\n",
    "        mov x29, sp\n",
    "    \"\"\"\n",
    "\n",
    "    epilog = \"\"\"\n",
    "        ldp x29, x30, [sp], #prologue_shift\n",
    "        ret\n",
    "    \"\"\"\n",
    "\n",
    "    escape_chars = '[]'\n",
    "\n",
    "    def unify(text, pattern = False):\n",
    "        if pattern:\n",
    "            for char in Comparator.escape_chars:\n",
    "                text = text.replace(f'{char}', fr'\\{char}')\n",
    "\n",
    "        text = text.replace('prologue_shift', Comparator.hex_pattern)\n",
    "\n",
    "        tokens = text.strip().split()\n",
    "\n",
    "        unified = ''\n",
    "        for t in tokens:\n",
    "            unified += t + ' '\n",
    "\n",
    "        return unified \n",
    "    \n",
    "    def compare_part(code, is_prolog = True, verbose = False):\n",
    "        unified_code = Comparator.unify(code)\n",
    "\n",
    "        pattern = getattr(Comparator, 'prolog' if is_prolog else 'epilog')\n",
    "        unified_pattern = Comparator.unify(pattern, True)\n",
    "\n",
    "        if verbose: \n",
    "            print(unified_code)\n",
    "            print(unified_pattern)\n",
    "\n",
    "        compiled_pattern = re.compile(unified_pattern, re.IGNORECASE)\n",
    "        return compiled_pattern.search(unified_code)\n",
    "\n",
    "    # def count_lines(chars, code, from_end = False):\n",
    "    #     lengths = []\n",
    "    #     for line in code.splitlines():\n",
    "    #         length = 0\n",
    "    #         for word in line.split():\n",
    "    #             length += len(word)\n",
    "    #         lengths += [length]\n",
    "\n",
    "    #     lengths = reversed(lengths) if from_end else lengths\n",
    "\n",
    "    #     lines = 0\n",
    "    #     for l in lengths:\n",
    "    #         if chars == 0:\n",
    "    #             return lines\n",
    "\n",
    "    #         chars -= l\n",
    "    #         lines += 1\n",
    "\n",
    "    #     assert False, 'Function detection failed'\n",
    "\n",
    "    def check_function(code):\n",
    "        match_p = Comparator.compare_part(code, True)\n",
    "        match_e = Comparator.compare_part(code, False)\n",
    "\n",
    "        if match_p and match_e:\n",
    "            span = (match_p.span()[0], match_e.span()[1])\n",
    "\n",
    "            if span == (0, len(code) - 1):\n",
    "                return True\n",
    "\n",
    "        assert  False \\\n",
    "                (span, len(code) - 1, 'Assignment conditions not fullfilled.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stp x29, x30, [sp, #-0x30]! mov x29, sp str w0, [sp, #0x1c] str w1, [sp, #0x18] ldr w1, [sp, #0x1c] ldr w0, [sp, #0x18] add w0, w1, w0 str w0, [sp, #0x2c] ldr w0, [sp, #0x1c] bl #0x24 adrp x0, #0 add x0, x0, #0 bl #0x30 ldr w0, [sp, #0x18] bl #0x38 adrp x0, #0 add x0, x0, #0 bl #0x44 ldr w0, [sp, #0x2c] bl #0x4c adrp x0, #0 add x0, x0, #0 bl #0x58 ldr w0, [sp, #0x2c] ldp x29, x30, [sp], #0x30 ret \n",
      "stp x29, x30, \\[sp, #-0x[0-9a-f]+\\]! mov x29, sp \n",
      "stp x29, x30, [sp, #-0x30]! mov x29, sp str w0, [sp, #0x1c] str w1, [sp, #0x18] ldr w1, [sp, #0x1c] ldr w0, [sp, #0x18] add w0, w1, w0 str w0, [sp, #0x2c] ldr w0, [sp, #0x1c] bl #0x24 adrp x0, #0 add x0, x0, #0 bl #0x30 ldr w0, [sp, #0x18] bl #0x38 adrp x0, #0 add x0, x0, #0 bl #0x44 ldr w0, [sp, #0x2c] bl #0x4c adrp x0, #0 add x0, x0, #0 bl #0x58 ldr w0, [sp, #0x2c] ldp x29, x30, [sp], #0x30 ret \n",
      "ldp x29, x30, \\[sp\\], #0x[0-9a-f]+ ret \n",
      "True\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[815], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m ElfFile\u001b[38;5;241m.\u001b[39mread_elf_header()\n\u001b[1;32m      9\u001b[0m ElfFile\u001b[38;5;241m.\u001b[39mread_section_headers()\n\u001b[0;32m---> 11\u001b[0m \u001b[43mElfFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_code_sections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# disassemble_code(section)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# assemble_code(None)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[653], line 47\u001b[0m, in \u001b[0;36mElfFile.find_code_sections\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sh\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msh_type\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# SHT_PROGBITS \u001b[39;00m\n\u001b[1;32m     46\u001b[0m     functions \u001b[38;5;241m=\u001b[39m Translator\u001b[38;5;241m.\u001b[39mcount_functions(sh\u001b[38;5;241m.\u001b[39msection_data)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     rela \u001b[38;5;241m=\u001b[39m ElfFile\u001b[38;5;241m.\u001b[39mlook_for_section(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.rela\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m sh\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rela:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input = 'test-aarch64.o'  \n",
    "output = 'out.o'\n",
    "good_output = 'test-aarch64-x64.o'  \n",
    "\n",
    "shutil.copy(input, output)\n",
    "\n",
    "ElfFile.setup(input)\n",
    "ElfFile.read_elf_header()\n",
    "ElfFile.read_section_headers()\n",
    "\n",
    "ElfFile.find_code_sections()\n",
    "\n",
    "# disassemble_code(section)\n",
    "# assemble_code(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "\n",
    "    def count_functions(code_section):\n",
    "        code = Translator.disassemble_code(code_section, show_offsets = False)\n",
    "        print(Comparator.check_function(code))\n",
    "\n",
    "    def disassemble_code(code_section, show_offsets = True, rela_section = None, verbose = False):\n",
    "        # AArch64 architecture\n",
    "        md = capstone.Cs(capstone.CS_ARCH_ARM64, capstone.CS_MODE_ARM)\n",
    "\n",
    "        instructions = md.disasm(code_section, 0)\n",
    "\n",
    "        code = \"\"\n",
    "        for insn in instructions:\n",
    "            off = f\"0x{insn.address:x}:\\t\" if show_offsets else \"\"\n",
    "            code_line = f\"{off}{insn.mnemonic}\\t{insn.op_str}\"\n",
    "\n",
    "            code += code_line + \"\\n\"\n",
    "\n",
    "            if verbose:\n",
    "                print(code_line)\n",
    "        \n",
    "        return code\n",
    "\n",
    "    def assemble_code(code):\n",
    "        # separate assembly instructions by ; or \\n\n",
    "        CODE = b\"INC ecx; DEC edx\"\n",
    "        \n",
    "        try:\n",
    "            ks = keystone.Ks(keystone.KS_ARCH_X86, keystone.KS_MODE_64)\n",
    "            encoding, count = ks.asm(CODE)\n",
    "            print(\"%s = %s (number of statements: %u)\" %(CODE, encoding, count))\n",
    "\n",
    "        except keystone.KsError as e:\n",
    "            print(\"ERROR: %s\" %e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElfFile:\n",
    "    data = None\n",
    "    section_headers = []\n",
    "    shstroff = None\n",
    "    symtab = None\n",
    "    rela_dict = {}\n",
    "\n",
    "    def setup(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            ElfFile.data = f.read()\n",
    "\n",
    "    def read_elf_header():\n",
    "        ElfHeader.read_elf_header()\n",
    "\n",
    "    def find_string(relative_offset):\n",
    "        str_offset = relative_offset + ElfFile.shstroff \n",
    "        str_end = ElfFile.data.find(b'\\x00', str_offset)\n",
    "        str_len = str_end - str_offset\n",
    "\n",
    "        str = struct.unpack(f'{str_len}s', ElfFile.data[str_offset : str_end])[0]\n",
    "\n",
    "        return str\n",
    "        \n",
    "    def read_section_headers():\n",
    "        for i in range(ElfHeader.get('e_shnum')):\n",
    "            offset = ElfHeader.get('e_shoff') + i * ElfHeader.get('e_shentsize')\n",
    "\n",
    "            ElfFile.section_headers += [SectionHeader(offset)]\n",
    "        \n",
    "        shstrns = ElfFile.section_headers[ElfHeader.get('e_shstrndx')]\n",
    "        ElfFile.shstroff = shstrns.get('sh_offset')\n",
    "\n",
    "        for sh in ElfFile.section_headers:\n",
    "            sh.set_name()\n",
    "            if (sh.name == b'.symtab'):\n",
    "                ElfFile.symtab = sh\n",
    "\n",
    "    def look_for_section(name):\n",
    "        for sh in ElfFile.section_headers:\n",
    "            if sh.name == name:\n",
    "                return sh\n",
    "\n",
    "    def find_code_sections():\n",
    "        for sh in ElfFile.section_headers: \n",
    "            if sh.get('sh_type')== 1:  # SHT_PROGBITS \n",
    "                functions = Translator.count_functions(sh.section_data)\n",
    "                assert False\n",
    "                rela = ElfFile.look_for_section(b'.rela' + sh.name)\n",
    "\n",
    "                if rela:\n",
    "                    rela_entries = Rela.collect_rela_entries(rela)\n",
    "\n",
    "                    for re in rela_entries:\n",
    "                        re.print()\n",
    "\n",
    "                print(rela.name if rela else '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
