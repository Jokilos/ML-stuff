{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnjs8SQNwQYr"
      },
      "source": [
        "# Variational AutoEncoder\n",
        "\n",
        "Task: Implement and train a probabilistic AutoEncoder called Variational AutoEncoder (VAE) on MNIST. A nice introduction to this topic is [here](https://www.jeremyjordan.me/variational-autoencoders/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JA2s1eIMuS2s"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "XsxCNmlfuT9C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "x_dim  = 784\n",
        "hidden_dim = 400\n",
        "latent_dim = 200\n",
        "\n",
        "lr = 0.001 # TODO\n",
        "\n",
        "epochs = 5 # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "GlRmJAkDuZDd"
      },
      "outputs": [],
      "source": [
        "dataset_path = 'datasets'\n",
        "mnist_transform = torchvision.transforms.Compose([ torchvision.transforms.ToTensor() ]) \n",
        "train_dataset = torchvision.datasets.MNIST(dataset_path, transform=mnist_transform, train=True, download=True)\n",
        "test_dataset  = torchvision.datasets.MNIST(dataset_path, transform=mnist_transform, train=False, download=True)\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Ee1nFayFubAX"
      },
      "outputs": [],
      "source": [
        "# Implement Encoder that consists of FC input_dim -> hidden_dim, FC hidden_dim -> hidden_dim, FC hidden_dim -> latent_dim\n",
        "# You can use LeakyReLU 0.2\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, latent_dim * 2)\n",
        "\n",
        "        self.lrelu = nn.LeakyReLU(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.lrelu(self.fc1(x))\n",
        "        x = self.ln1(x)\n",
        "\n",
        "        x = self.lrelu(self.fc2(x))\n",
        "        x = self.ln2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Qe6mbSECuc9z"
      },
      "outputs": [],
      "source": [
        "# Implement Decoder that consists of FC latent_dim -> hidden_dim, FC hidden_dim -> hidden_dim, FC hidden_dim -> output_dim\n",
        "# You can use Sigmoid and LeakyReLU 0.2\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.lrelu = nn.LeakyReLU(0.2)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.lrelu(self.fc1(x))\n",
        "        x = self.ln1(x)\n",
        "\n",
        "        x = self.lrelu(self.fc2(x))\n",
        "        x = self.ln2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return self.sigm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "TJ0UJ_rwueeD"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, Encoder, Decoder, latent_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.Encoder = Encoder\n",
        "        self.Decoder = Decoder\n",
        "        \n",
        "    def reparameterization(self, mean, logvar):\n",
        "        stddev = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(stddev)\n",
        "\n",
        "        return eps * stddev + mean \n",
        "                \n",
        "    def forward(self, x):\n",
        "        x = self.Encoder(x)\n",
        "\n",
        "        x_logvar = x[:, :self.latent_dim]\n",
        "        x_mu = x[:, self.latent_dim:]\n",
        "\n",
        "        assert x_logvar.shape == x_mu.shape, (x_logvar.shape, x_mu.shape)\n",
        "        \n",
        "        x = self.reparameterization(x_mu, x_logvar)\n",
        "\n",
        "        x = self.Decoder(x)\n",
        "\n",
        "        return x, x_mu, x_logvar "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-HFXNwn4ugNP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "784 400 100\n"
          ]
        }
      ],
      "source": [
        "latent_dim = int(200 / 2)\n",
        "\n",
        "print(x_dim, hidden_dim, latent_dim)\n",
        "\n",
        "encoder = Encoder(\n",
        "    input_dim = x_dim,\n",
        "    hidden_dim = hidden_dim,\n",
        "    latent_dim = latent_dim,\n",
        ")\n",
        "\n",
        "decoder = Decoder(\n",
        "    latent_dim = latent_dim,\n",
        "    hidden_dim = hidden_dim,\n",
        "    output_dim = x_dim,\n",
        ")\n",
        "\n",
        "model = Model(Encoder = encoder, Decoder = decoder, latent_dim = latent_dim).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "VGAr6r06qUzh"
      },
      "outputs": [],
      "source": [
        "# Loss function for the Gaussian distribution prior is presented in https://arxiv.org/pdf/1907.08956.pdf, Eq. 43.\n",
        "\n",
        "def loss_function(x, x_hat, mu, logvar):\n",
        "    recons_loss = torch.nn.functional.cross_entropy(x, x_hat)\n",
        "\n",
        "    KLD = torch.sum(1 + logvar - mu ** 2 - logvar.exp(), dim = 1)\n",
        "    KLD = torch.mean(KLD, dim = 0)\n",
        "\n",
        "    return recons_loss + KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N1LesRxuj0n"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    overall_loss = 0\n",
        "    for i, (x, _) in enumerate(train_loader):\n",
        "        x = x.view(batch_size, x_dim)\n",
        "        x = x.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_hat, mean, log_var = model(x)\n",
        "        loss = loss_function(x, x_hat, mean, log_var)\n",
        "        \n",
        "        overall_loss += loss.item()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print(\"\\tEpoch\", epoch + 1, \"Average Loss: \", overall_loss / (len(train_loader) * batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "2xJLMVqHunA4"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, _) in enumerate(test_loader):\n",
        "        x = x.view(batch_size, x_dim)\n",
        "        x = x.to(device)\n",
        "        x_hat, _, _ = model(x)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9dIf6alupCG"
      },
      "outputs": [],
      "source": [
        "def show_images(x, n_samples=3):\n",
        "    x = x.view(batch_size, 28, 28) \n",
        "    for i in range(n_samples):\n",
        "      fig = plt.figure()\n",
        "      plt.imshow(x[i].cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45ttudoOusFG"
      },
      "outputs": [],
      "source": [
        "show_images(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJhbyHaisGD5"
      },
      "outputs": [],
      "source": [
        "show_images(x_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V54aShcYuuH0"
      },
      "outputs": [],
      "source": [
        "# TODO: sample noise, generate new images from noise and show generted images"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "VAE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
