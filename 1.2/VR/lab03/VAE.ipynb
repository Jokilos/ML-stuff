{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnjs8SQNwQYr"
      },
      "source": [
        "# Variational AutoEncoder\n",
        "\n",
        "Task: Implement and train a probabilistic AutoEncoder called Variational AutoEncoder (VAE) on MNIST. A nice introduction to this topic is [here](https://www.jeremyjordan.me/variational-autoencoders/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JA2s1eIMuS2s"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "XsxCNmlfuT9C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "x_dim  = 784\n",
        "hidden_dim = 400\n",
        "latent_dim = 200\n",
        "\n",
        "lr = 0.001 # TODO\n",
        "\n",
        "epochs = 5 # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "GlRmJAkDuZDd"
      },
      "outputs": [],
      "source": [
        "dataset_path = 'datasets'\n",
        "mnist_transform = torchvision.transforms.Compose([ torchvision.transforms.ToTensor() ]) \n",
        "train_dataset = torchvision.datasets.MNIST(dataset_path, transform=mnist_transform, train=True, download=True)\n",
        "test_dataset  = torchvision.datasets.MNIST(dataset_path, transform=mnist_transform, train=False, download=True)\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Ee1nFayFubAX"
      },
      "outputs": [],
      "source": [
        "# Implement Encoder that consists of FC input_dim -> hidden_dim, FC hidden_dim -> hidden_dim, FC hidden_dim -> latent_dim\n",
        "# You can use LeakyReLU 0.2\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, latent_dim * 2)\n",
        "\n",
        "        self.lrelu = nn.LeakyReLU(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.lrelu(self.fc1(x))\n",
        "        x = self.ln1(x)\n",
        "\n",
        "        x = self.lrelu(self.fc2(x))\n",
        "        x = self.ln2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Qe6mbSECuc9z"
      },
      "outputs": [],
      "source": [
        "# Implement Decoder that consists of FC latent_dim -> hidden_dim, FC hidden_dim -> hidden_dim, FC hidden_dim -> output_dim\n",
        "# You can use Sigmoid and LeakyReLU 0.2\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.lrelu = nn.LeakyReLU(0.2)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.lrelu(self.fc1(x))\n",
        "        x = self.ln1(x)\n",
        "\n",
        "        x = self.lrelu(self.fc2(x))\n",
        "        x = self.ln2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return self.sigm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "TJ0UJ_rwueeD"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, Encoder, Decoder, latent_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.Encoder = Encoder\n",
        "        self.Decoder = Decoder\n",
        "        \n",
        "    def reparameterization(self, mean, logvar):\n",
        "        stddev = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(stddev)\n",
        "\n",
        "        return eps * stddev + mean \n",
        "                \n",
        "    def forward(self, x):\n",
        "        x = self.Encoder(x)\n",
        "\n",
        "        x_logvar = x[:, :self.latent_dim]\n",
        "        x_mu = x[:, self.latent_dim:]\n",
        "\n",
        "        assert x_logvar.shape == x_mu.shape, (x_logvar.shape, x_mu.shape)\n",
        "        \n",
        "        x = self.reparameterization(x_mu, x_logvar)\n",
        "\n",
        "        x = self.Decoder(x)\n",
        "\n",
        "        return x, x_mu, x_logvar "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "-HFXNwn4ugNP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "784 400 100\n"
          ]
        }
      ],
      "source": [
        "latent_dim = int(200 / 2)\n",
        "\n",
        "print(x_dim, hidden_dim, latent_dim)\n",
        "\n",
        "encoder = Encoder(\n",
        "    input_dim = x_dim,\n",
        "    hidden_dim = hidden_dim,\n",
        "    latent_dim = latent_dim,\n",
        ")\n",
        "\n",
        "decoder = Decoder(\n",
        "    latent_dim = latent_dim,\n",
        "    hidden_dim = hidden_dim,\n",
        "    output_dim = x_dim,\n",
        ")\n",
        "\n",
        "model = Model(Encoder = encoder, Decoder = decoder, latent_dim = latent_dim).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGAr6r06qUzh"
      },
      "outputs": [],
      "source": [
        "# Loss function for the Gaussian distribution prior is presented in https://arxiv.org/pdf/1907.08956.pdf, Eq. 43.\n",
        "\n",
        "def loss_function(x, x_hat, mu, logvar):\n",
        "    recons_loss = torch.nn.functional.cross_entropy(x, x_hat)\n",
        "\n",
        "    # def ts:\n",
        "        # return torch.sum(x)\n",
        "    # print(ts(logvar.exp()))\n",
        "    # print(ts(mu ** 2))\n",
        "    # print(ts(logvar))\n",
        "\n",
        "    kld_weight = 1.5\n",
        "\n",
        "    KLD = torch.sum(1 + logvar - mu ** 2 - logvar.exp(), dim = 1)\n",
        "    KLD = kld_weight * torch.mean(-0.5 * KLD, dim = 0)\n",
        "\n",
        "    print(f'{recons_loss=} {KLD=}')\n",
        "\n",
        "    return recons_loss + KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "4N1LesRxuj0n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0017, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0010, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0020, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0012, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0010, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0017, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0016, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0009, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0017, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0015, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0008, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0014, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0013, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0007, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0012, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0010, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n",
            "recons_loss=tensor(0.0011, grad_fn=<DivBackward1>) KLD=tensor(0.0006, grad_fn=<MeanBackward1>)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[91], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(x, x_hat, mean, log_var)\n\u001b[1;32m     14\u001b[0m     overall_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Loss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, overall_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mlen\u001b[39m(train_loader) \u001b[38;5;241m*\u001b[39m batch_size))\n",
            "File \u001b[0;32m~/Git/ML-stuff/venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Git/ML-stuff/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Git/ML-stuff/venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    overall_loss = 0\n",
        "    for i, (x, _) in enumerate(train_loader):\n",
        "        x = x.view(batch_size, x_dim)\n",
        "        x = x.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_hat, mean, log_var = model(x)\n",
        "        loss = loss_function(x, x_hat, mean, log_var)\n",
        "        \n",
        "        overall_loss += loss.item()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print(\"\\tEpoch\", epoch + 1, \"Average Loss: \", overall_loss / (len(train_loader) * batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "2xJLMVqHunA4"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, _) in enumerate(test_loader):\n",
        "        x = x.view(batch_size, x_dim)\n",
        "        x = x.to(device)\n",
        "        x_hat, _, _ = model(x)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "G9dIf6alupCG"
      },
      "outputs": [],
      "source": [
        "def show_images(x, n_samples=3):\n",
        "    x = x.view(batch_size, 28, 28) \n",
        "    for i in range(n_samples):\n",
        "      plt.figure()\n",
        "      plt.imshow(x[i].cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "45ttudoOusFG"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_images(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "yJhbyHaisGD5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_images(x_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V54aShcYuuH0"
      },
      "outputs": [],
      "source": [
        "# TODO: sample noise, generate new images from noise and show generted images"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "VAE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
