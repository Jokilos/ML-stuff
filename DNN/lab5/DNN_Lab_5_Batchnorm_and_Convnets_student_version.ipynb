{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcTwzhX8fBqs"
   },
   "source": [
    "Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "This exercise covers two aspects:\n",
    "* In tasks 1-6 you will implement mechanisms that allow training deeper models (better initialization, batch normalization). Note that for dropout and batch norm you are expected to implement it yourself without relying on ready-made components from Pytorch. After doing each of the tasks you can look at the plots and check how your changes impact gradients of network layers.\n",
    "* In task 7 you will implement a convnet using [conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
    "\n",
    "\n",
    "Tasks:\n",
    "1. Check that the given implementation reaches 95% test accuracy for\n",
    "   architecture input-64-64-10 in a few thousand batches.\n",
    "2. Improve initialization and check that the network learns much faster\n",
    "   and reaches over 97% test accuracy. A good basic initialization scheme is so-called Glorot initialization. For a set of weights going from a layer with $n_{in}$ neurons to a layer with $n_{out}$ neurons, it samples each weight from normal distribution with $0$ mean and standard deviation of $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$.  \n",
    "Check how better initialization changes distribution of gradients at the first epoch.\n",
    "3. Check, that with proper initialization we can train architecture\n",
    "   input-64-64-64-64-64-10, while with bad initialization it does\n",
    "   not even get off the ground.\n",
    "4. Add dropout implemented in pytorch (but without using torch.nn.Dropout)\n",
    "5. Check that with 10 hidden layers (64 units each) even with proper\n",
    "    initialization the network has a hard time to start learning.\n",
    "6. Implement batch normalization (use train mode also for testing - it should perform well enough):\n",
    "    * compute batch mean and variance\n",
    "    * add new variables beta and gamma\n",
    "    * check that the networks learns much faster for 5 layers\n",
    "    * check that the network learns even for 10 hidden layers.\n",
    "    * check how gradients change in comparison to network without batch norm.\n",
    "7. So far we worked with a fully connected network. Design and implement in pytorch (by using pytorch functions) a simple convolutional network and achieve 99% test accuracy. The architecture is up to you, but even a few convolutional layers should be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IYAsziKffBFV"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "collapsed": true,
    "id": "D2cTAah4oMkJ"
   },
   "outputs": [],
   "source": [
    "#@title Visualize gradients\n",
    "\n",
    "class GradientVisualizer:\n",
    "    def __init__(self, net, num_epochs):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.linear_layers = self.get_linear_layers(net)\n",
    "\n",
    "        self.grad_to_weight_fig = None\n",
    "        self.grads_in_layers_fig = None\n",
    "        self.grads_at_epochs_fig = None\n",
    "        self.init_figures()\n",
    "\n",
    "    def get_linear_layers(self, net):\n",
    "        linear_layers = []\n",
    "        for field in net.__dict__['_modules'].values():\n",
    "            if isinstance(field, Linear):\n",
    "                linear_layers.append(field)\n",
    "            if isinstance(field, nn.ModuleList):\n",
    "                for module in field:\n",
    "                    if isinstance(module, Linear):\n",
    "                        linear_layers.append(module)\n",
    "\n",
    "        assert linear_layers, \\\n",
    "        ('No linear layers found. Linear layers should be parameters of the network or they '\n",
    "        'should be placed in a ModuleList which is a parameter of the network.')\n",
    "        return linear_layers\n",
    "\n",
    "    def get_epochs_for_one_layer(self):\n",
    "        \"\"\"\n",
    "        We want to show gradient distributions from up to 7 selected epochs\n",
    "        for one linear layer.\n",
    "        \"\"\"\n",
    "        if self.num_epochs < 7:\n",
    "            return list(range(self.num_epochs))\n",
    "        else:\n",
    "            return torch.linspace(0, self.num_epochs - 1, 7).int().tolist()\n",
    "\n",
    "    def get_three_epochs(self):\n",
    "        \"\"\"\n",
    "        We want to show gradients distributions from all layers at each of\n",
    "        three epochs: first, middle and last.\n",
    "        \"\"\"\n",
    "        return [0, self.num_epochs // 2, self.num_epochs - 1]\n",
    "\n",
    "    def rgb_to_rgba(self, rgb_color, epoch):\n",
    "        \"\"\"\n",
    "        Value of epoch parameter determines how transparent color should be\n",
    "        in comparison to others.\n",
    "        Colors for earlier epochs should be more transparent/less visible.\n",
    "        \"\"\"\n",
    "        return f'rgba{rgb_color[3:-1]},{0.6 * (epoch + 1) / self.num_epochs + 0.15})'\n",
    "\n",
    "    def init_figures(self):\n",
    "        # Initialize figure with gradient to weight ratio plot\n",
    "        fig = go.Figure()\n",
    "        fig.update_layout(\n",
    "            title='Gradient standard deviation to weight standard deviation ratio', title_x=0.5,\n",
    "            xaxis_title='Epoch',\n",
    "            yaxis_title='Gradient to weight ratio (log scale)',\n",
    "            height=400, width=1500, margin=dict(b=10, t=60)\n",
    "        )\n",
    "        fig.update_yaxes(type='log')\n",
    "        for i in range(len(self.linear_layers)):\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[], y=[],\n",
    "                mode='lines+markers', name=f'Linear layer {i}'\n",
    "            ))\n",
    "\n",
    "        self.grad_to_weight_fig = go.FigureWidget(fig)\n",
    "        display(self.grad_to_weight_fig)\n",
    "\n",
    "        # Initialize figure visualizing gradient distributions in layers\n",
    "        num_rows = (len(self.linear_layers) - 1) // 3 + 1\n",
    "        fig = make_subplots(\n",
    "            rows=num_rows, cols=3,\n",
    "            subplot_titles=[f'Linear layer {i}' for i in range(len(self.linear_layers))],\n",
    "            vertical_spacing=0.2 / num_rows\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            title='Comparison between epochs of gradient distributions in layers', title_x=0.5,\n",
    "            height=num_rows * 400, width=1500, margin=dict(b=10, t=60)\n",
    "        )\n",
    "\n",
    "        colors, _ = px.colors.convert_colors_to_same_type(2 * px.colors.qualitative.Plotly)\n",
    "        for layer_num in range(len(self.linear_layers)):\n",
    "            row = layer_num // 3 + 1\n",
    "            col = layer_num % 3 + 1\n",
    "            fig.update_xaxes(\n",
    "                title_text='Gradient value', range=(-0.1, 0.1), row=row, col=col\n",
    "            )\n",
    "            fig.update_yaxes(\n",
    "                title_text='Density (log scale)', type='log', row=row, col=col\n",
    "            )\n",
    "\n",
    "            # Create empty traces and update them later with actual gradient distributions.\n",
    "            # Unfortunately, we cannot add new traces dynamically because Colab has problem\n",
    "            # with widgets from plotly (traces added dynamically are rendered twice).\n",
    "            for epoch in self.get_epochs_for_one_layer():\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        mode='lines', name=f'Epoch {epoch + 1}',\n",
    "                        line=dict(color=self.rgb_to_rgba(colors[layer_num], epoch)),\n",
    "                        legendgroup=layer_num\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "\n",
    "        self.grads_in_layers_fig = go.FigureWidget(fig)\n",
    "        display(self.grads_in_layers_fig)\n",
    "\n",
    "        # Initialize figure comparing gradient distributions between layers at the\n",
    "        # first, middle and last epoch\n",
    "        selected_epochs_indices = self.get_three_epochs()\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=3,\n",
    "            subplot_titles=[f'Epoch {epoch + 1}' for epoch in selected_epochs_indices]\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            title='Comparison between layers of gradient distributions at epochs', title_x=0.5,\n",
    "            height=400, width=1500, margin=dict(b=10, t=60)\n",
    "        )\n",
    "\n",
    "        for col, epoch in enumerate(selected_epochs_indices, 1):\n",
    "            fig.update_yaxes(title_text='Density (log scale)', type='log', row=1, col=col)\n",
    "            fig.update_xaxes(\n",
    "                title_text='Gradient value',\n",
    "                range=(-0.05, 0.05) if epoch != 0 else (-1, 1),\n",
    "                row=1, col=col\n",
    "            )\n",
    "\n",
    "            # Create empty traces and update them later with actual gradient distributions.\n",
    "            for layer_num in range(len(self.linear_layers)):\n",
    "                fig.append_trace(\n",
    "                    go.Scatter(\n",
    "                        mode='lines', name=f'Linear layer {layer_num}',\n",
    "                        line=dict(color=colors[layer_num]), showlegend=(col == 1)\n",
    "                    ),\n",
    "                    row=1, col=col\n",
    "                )\n",
    "\n",
    "        self.grads_at_epochs_fig = go.FigureWidget(fig)\n",
    "        display(self.grads_at_epochs_fig)\n",
    "\n",
    "    def visualize_gradients(self, lr, epoch, batch_idx):\n",
    "        # It is enough to use gradients calculated for the first batch.\n",
    "        if batch_idx != 0:\n",
    "            return\n",
    "\n",
    "        epoch_grads = []\n",
    "        epoch_grad_to_weight_ratios = []\n",
    "        for layer in self.linear_layers:\n",
    "            epoch_grads.append(layer.weight.grad.flatten().detach())\n",
    "            epoch_grad_to_weight_ratios.append(\n",
    "                (lr * layer.weight.grad.std() / layer.weight.std()).item()\n",
    "            )\n",
    "\n",
    "        # Update figure with gradient to weight ratio plot\n",
    "        for i, grad_to_weight_ratio in enumerate(epoch_grad_to_weight_ratios):\n",
    "            x = self.grad_to_weight_fig.data[i].x\n",
    "            next_x_val = x[-1] + 1 if x else 1\n",
    "            self.grad_to_weight_fig.data[i].x += (next_x_val, )\n",
    "            self.grad_to_weight_fig.data[i].y += (grad_to_weight_ratio, )\n",
    "\n",
    "        # Update figure visualizing gradient distributions in layers\n",
    "        selected_epochs = self.get_epochs_for_one_layer()\n",
    "        if epoch in selected_epochs:\n",
    "            epoch_idx = selected_epochs.index(epoch)\n",
    "            for layer_num, layer_grad in enumerate(epoch_grads):\n",
    "                trace_idx = layer_num * len(selected_epochs) + epoch_idx\n",
    "                hy, hx = torch.histogram(layer_grad, bins=50, density=True)\n",
    "                hy = hy / max(hy) + 0.001\n",
    "                self.grads_in_layers_fig.data[trace_idx].x = hx[:-1].tolist()\n",
    "                self.grads_in_layers_fig.data[trace_idx].y = hy.tolist()\n",
    "\n",
    "        # Update figure visualizing gradient distributions at epochs\n",
    "        selected_epochs = self.get_three_epochs()\n",
    "        if epoch in selected_epochs:\n",
    "            epoch_idx = selected_epochs.index(epoch)\n",
    "            for layer_num, layer_grad in enumerate(epoch_grads):\n",
    "                trace_idx = epoch_idx * len(self.linear_layers) + layer_num\n",
    "                hy, hx = torch.histogram(layer_grad, bins=50, density=True)\n",
    "                hy = hy / max(hy) + 0.001\n",
    "                self.grads_at_epochs_fig.data[trace_idx].x = hx[:-1].tolist()\n",
    "                self.grads_at_epochs_fig.data[trace_idx].y = hy.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DMtap4QCfBH8"
   },
   "outputs": [],
   "source": [
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, glorot=False, batch_norm=False, eps=1e-6):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.gamma = Parameter(torch.Tensor(in_features))\n",
    "        self.beta = Parameter(torch.Tensor(in_features))\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = Parameter(torch.Tensor(out_features))\n",
    "        self.eps = eps\n",
    "        self.glorot = glorot\n",
    "        self.bn = batch_norm\n",
    "        self.reset_glorot()\n",
    "\n",
    "    def reset_glorot(self):\n",
    "        if self.glorot:\n",
    "            stddev = (2 / (self.in_features + self.out_features)) ** (1/2)\n",
    "        else:\n",
    "            stddev = 0.25\n",
    "\n",
    "        self.weight.data.normal_(mean = 0, std = stddev)\n",
    "        init.zeros_(self.beta)\n",
    "        init.zeros_(self.bias)\n",
    "        init.ones_(self.gamma)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.bn:\n",
    "            batch_size, _ = x.shape \n",
    "        \n",
    "            means = (1 / batch_size) * torch.sum(x, dim = 0)\n",
    "            means = means.repeat(batch_size, 1)\n",
    "            variances = (1 / batch_size) * torch.sum((x - means)**2, dim = 0)\n",
    "            variances = variances.repeat(batch_size, 1)\n",
    "\n",
    "            numerator = x - means\n",
    "            denominator = (variances + self.eps)**(1/2)\n",
    "            x = self.gamma * (numerator / denominator) + self.beta\n",
    "\n",
    "            return x.matmul(self.weight.t())\n",
    "        else:\n",
    "            return x.matmul(self.weight.t()) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(torch.nn.Module):\n",
    "    def __init__(self, features, p=0.95):\n",
    "        super(Dropout, self).__init__()\n",
    "        self.features = features\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        dropout = torch.Tensor(x.shape)\n",
    "        dropout.bernoulli_(p = self.p)\n",
    "        new_x = x * dropout\n",
    "\n",
    "        return new_x * (1/self.p)\n",
    "    \n",
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, sizes, glorot=False, dropout=False, batch_norm=False):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        dropouts = [Dropout(s) for s in sizes[1:-1]] + [Identity()]\n",
    "        sizes = np.array(sizes)\n",
    "        sizes2 = np.vstack([sizes[:-1], sizes[1:]]).T\n",
    "        modules = [Linear(*s, glorot=glorot, batch_norm=batch_norm) for s in sizes2]\n",
    "\n",
    "        self.fcs = nn.ModuleList(modules)\n",
    "        self.dps = nn.ModuleList(dropouts)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        activasion_funs = [F.relu] * (len(self.fcs) - 1) + [lambda x : x]\n",
    "\n",
    "        x = x.view(-1, 28 * 28)\n",
    "\n",
    "        tuple_list = zip(self.fcs, self.dps, activasion_funs)\n",
    "\n",
    "        for fc, dp, activation_fun in tuple_list:\n",
    "            x = activation_fun(fc(x))\n",
    "\n",
    "            if self.dropout:\n",
    "                x = dp(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DropoutNet, self).__init__()\n",
    "        self.fc1 = Linear(784, 64)\n",
    "        self.dp1 = Dropout(64)\n",
    "        self.fc2 = Linear(64, 64)\n",
    "        self.dp2 = Dropout(64)\n",
    "        self.fc3 = Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dp1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class BatchNormNet(nn.Module):\n",
    "    def __init__(self, dropout=False):\n",
    "        super(BatchNormNet, self).__init__()\n",
    "        self.fc1 = Linear(784, 64, True)\n",
    "        self.dp1 = Dropout(64) if dropout else Identity()\n",
    "        self.fc2 = Linear(64, 64, True)\n",
    "        self.dp2 = Dropout(64) if dropout else Identity()\n",
    "        self.fc3 = Linear(64, 10, True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dp1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WgfUP23AfBMd"
   },
   "outputs": [],
   "source": [
    "class MnistTrainer(object):\n",
    "    def __init__(self, batch_size):\n",
    "        transform = transforms.Compose(\n",
    "                [transforms.ToTensor()])\n",
    "        self.trainset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            download=True,\n",
    "            train=True,\n",
    "            transform=transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(\n",
    "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "        self.testset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True, transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(\n",
    "            self.testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    def train(self, net, gradient_visualizer, epochs=20, lr=0.05, momentum=0.9):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.trainloader):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                gradient_visualizer.visualize_gradients(lr, epoch, i)\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in self.testloader:\n",
    "                    images, labels = data\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "                total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wO3ooSNUHiQz"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m hidden_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      6\u001b[0m net \u001b[38;5;241m=\u001b[39m Net([\u001b[38;5;241m784\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m64\u001b[39m] \u001b[38;5;241m*\u001b[39m hidden_layers \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m10\u001b[39m], glorot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, batch_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m gradient_visualizer \u001b[38;5;241m=\u001b[39m \u001b[43mGradientVisualizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m, in \u001b[0;36mGradientVisualizer.__init__\u001b[0;34m(self, net, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrads_in_layers_fig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrads_at_epochs_fig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_figures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 102\u001b[0m, in \u001b[0;36mGradientVisualizer.init_figures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Create empty traces and update them later with actual gradient distributions.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Unfortunately, we cannot add new traces dynamically because Colab has problem\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# with widgets from plotly (traces added dynamically are rendered twice).\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_epochs_for_one_layer():\n\u001b[1;32m     99\u001b[0m         fig\u001b[38;5;241m.\u001b[39madd_trace(\n\u001b[1;32m    100\u001b[0m             go\u001b[38;5;241m.\u001b[39mScatter(\n\u001b[1;32m    101\u001b[0m                 mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m--> 102\u001b[0m                 line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrgb_to_rgba(\u001b[43mcolors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_num\u001b[49m\u001b[43m]\u001b[49m, epoch)),\n\u001b[1;32m    103\u001b[0m                 legendgroup\u001b[38;5;241m=\u001b[39mlayer_num\n\u001b[1;32m    104\u001b[0m             ),\n\u001b[1;32m    105\u001b[0m             row\u001b[38;5;241m=\u001b[39mrow, col\u001b[38;5;241m=\u001b[39mcol\n\u001b[1;32m    106\u001b[0m         )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrads_in_layers_fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigureWidget(fig)\n\u001b[1;32m    109\u001b[0m display(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrads_in_layers_fig)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "epochs = 10\n",
    "\n",
    "# no glorot - crashes on 7\n",
    "# with glorot - sometimes crashes on ~15\n",
    "# glorot + batchnorm - easily trains on 19\n",
    "# cannot test highet bcs of some bug in gradient visualizer ;(\n",
    "hidden_layers = 19\n",
    "net = Net([784] + [64] * hidden_layers + [10], glorot = True, dropout = False, batch_norm = True)\n",
    "gradient_visualizer = GradientVisualizer(net, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.488\n",
      "[1,   200] loss: 0.837\n",
      "[1,   300] loss: 0.643\n",
      "[1,   400] loss: 0.523\n",
      "Accuracy of the network on the 10000 test images: 87.98 %\n",
      "[2,   100] loss: 0.439\n",
      "[2,   200] loss: 0.395\n",
      "[2,   300] loss: 0.375\n",
      "[2,   400] loss: 0.337\n",
      "Accuracy of the network on the 10000 test images: 91.05 %\n",
      "[3,   100] loss: 0.311\n",
      "[3,   200] loss: 0.296\n",
      "[3,   300] loss: 0.293\n",
      "[3,   400] loss: 0.290\n",
      "Accuracy of the network on the 10000 test images: 92.38 %\n",
      "[4,   100] loss: 0.250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MnistTrainer(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_visualizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m, in \u001b[0;36mMnistTrainer.train\u001b[0;34m(self, net, gradient_visualizer, epochs, lr, momentum)\u001b[0m\n\u001b[1;32m     27\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Git/ML-stuff/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Git/ML-stuff/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m tuple_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfcs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdps, activasion_funs)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fc, dp, activation_fun \u001b[38;5;129;01min\u001b[39;00m tuple_list:\n\u001b[0;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m activation_fun(\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout:\n\u001b[1;32m     28\u001b[0m         x \u001b[38;5;241m=\u001b[39m dp(x)\n",
      "File \u001b[0;32m~/Git/ML-stuff/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Git/ML-stuff/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m variances \u001b[38;5;241m=\u001b[39m variances\u001b[38;5;241m.\u001b[39mrepeat(batch_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m numerator \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m means\n\u001b[0;32m---> 36\u001b[0m denominator \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mvariances\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m (numerator \u001b[38;5;241m/\u001b[39m denominator) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mt())\n",
      "File \u001b[0;32m~/Git/ML-stuff/venv/lib/python3.12/site-packages/torch/_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = MnistTrainer(batch_size=128)\n",
    "trainer.train(net, gradient_visualizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
