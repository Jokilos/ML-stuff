{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJ-w7K4eu6SK"
   },
   "source": [
    "# Logistic regression\n",
    "\n",
    "In this exercise you will train a logistic regression model via gradient descent in two simple scenarios.\n",
    "\n",
    "The general setup is as follows:\n",
    "* we are given a set of pairs $(x, y)$, where $x \\in R^D$ is a vector of real numbers representing the features, and $y \\in \\{0,1\\}$ is the target,\n",
    "* for a given $x$ we model the probability of $y=1$ by $h(x):=g(w^Tx)$, where $g$ is the sigmoid function: $g(z) = \\frac{1}{1+e^{-z}}$,\n",
    "* to find the right $w$ we will optimize the so called logarithmic loss: $J(w) = -\\frac{1}{n}\\sum_{i=1}^n y_i \\log{h(x_i)} + (1-y_i) \\log{(1-h(x_i))}$,\n",
    "* with the loss function in hand we can improve our guesses iteratively:\n",
    "    * $w_j^{t+1} = w_j^t - \\text{step\\_size} \\cdot \\frac{\\partial J(w)}{\\partial w_j}$,\n",
    "* we can end the process after some predefined number of epochs (or when the changes are no longer meaningful)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xt2z7CdJu6SQ"
   },
   "source": [
    "Let's start with the simplest example - linear separated points on a plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 808,
     "status": "ok",
     "timestamp": 1728923474172,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "Wg_d38Fou6SU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# these parametrize the line\n",
    "a = 0.3\n",
    "b = -0.2\n",
    "c = 0.001\n",
    "\n",
    "# True/False mapping\n",
    "def lin_rule(x, noise=0.):\n",
    "    return a * x[0] + b * x[1] + c + noise < 0.\n",
    "\n",
    "# Just for plotting\n",
    "def get_y_fun(a, b, c):\n",
    "    def y(x):\n",
    "        return - x * a / b - c / b\n",
    "    return y\n",
    "\n",
    "lin_fun = get_y_fun(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728923474927,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "ZZEHHKP8u6Si",
    "outputId": "d5222231-bb8d-4d65-c1f0-a3890600bc8f"
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "\n",
    "n = 500\n",
    "range_points = 1\n",
    "sigma = 0.05\n",
    "\n",
    "X = range_points * 2 * (np.random.rand(n, 2) - 0.5)\n",
    "y = [lin_rule(x, sigma * np.random.normal()) for x in X]\n",
    "\n",
    "print(X[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoTCKl3Yu6St"
   },
   "source": [
    "Let's plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 17566,
     "status": "ok",
     "timestamp": 1728923493294,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "qc99EecDu6Sw",
    "outputId": "9009d36d-5542-4876-e16b-5b6a6d49d486"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# plotly has a problem with coloring boolean values, hence stringify\n",
    "# see https://community.plotly.com/t/plotly-express-scatter-color-not-showing/25962\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n",
    "x_range = [np.min(X[:, 0]), np.max(X[:, 1])]\n",
    "fig.add_scatter(x=x_range, y=list(map(lin_fun, x_range)), name='ground truth border')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vq3J7fZpu6S4"
   },
   "source": [
    "Now, let's implement and train a logistic regression model. You should obtain accuracy of at least 96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGdRE3AaCyE1"
   },
   "source": [
    "\n",
    "The general setup is as follows:\n",
    "* we are given a set of pairs $(x, y)$, where $x \\in R^D$ is a vector of real numbers representing the features, and $y \\in \\{0,1\\}$ is the target,\n",
    "* for a given $x$ we model the probability of $y=1$ by $h(x):=g(w^Tx)$, where $g$ is the sigmoid function: $g(z) = \\frac{1}{1+e^{-z}}$,\n",
    "* to find the right $w$ we will optimize the so called logarithmic loss: $J(w) = -\\frac{1}{n}\\sum_{i=1}^n y_i \\log{h(x_i)} + (1-y_i) \\log{(1-h(x_i))}$,\n",
    "* with the loss function in hand we can improve our guesses iteratively:\n",
    "    * $w_j^{t+1} = w_j^t - \\text{step\\_size} \\cdot \\frac{\\partial J(w)}{\\partial w_j}$,\n",
    "* we can end the process after some predefined number of epochs (or when the changes are no longer meaningful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728923493295,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "Lw-eg0x0u6S6",
    "outputId": "af55e23b-a5ad-4e6b-cccd-9f0311e2c178"
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "# TODO: Implement logistic regression and compute its accuracy #\n",
    "################################################################\n",
    "features = 3\n",
    "\n",
    "lr = 5 # step size\n",
    "treshold = 1/2\n",
    "n_epochs = 100 # number of passes over the training data\n",
    "\n",
    "x = np.hstack([np.ones(n).reshape(n,1), X])\n",
    "w = np.array([0.001] * features).reshape(-1,1)\n",
    "y_ = np.array(y).reshape(n,1)\n",
    "\n",
    "def sigm(z):\n",
    "    return 1/(1+np.e**(-z))\n",
    "\n",
    "def h(x, w):\n",
    "    #print(sigm(x @ w)[:10])\n",
    "    return sigm(x @ w)\n",
    "\n",
    "def log_loss_eval(x, w_vec, y_vec):\n",
    "\n",
    "    #here boolean values automatically cast\n",
    "    arr = (y_vec * np.log(h(x, w_vec)) + (1 - y_vec) * np.log(1 - h(x, w_vec)))\n",
    "\n",
    "    #print(arr[:10])\n",
    "    return -1/n * np.sum(arr)\n",
    "\n",
    "log_loss_eval(x, w, y_)\n",
    "\n",
    "def predict(w, x=x):\n",
    "    return h(x, w) > treshold\n",
    "\n",
    "losses = [log_loss_eval(x, w, y_)]\n",
    "\n",
    "for i in range(n_epochs):\n",
    "\n",
    "    yhat = h(x, w)\n",
    "    dJdwj = (np.sum((yhat - y_) * x, axis = 0))\n",
    "\n",
    "    new_w = w - (1/n) * (lr * dJdwj).reshape(-1, 1)\n",
    "    w = new_w\n",
    "\n",
    "    loss = log_loss_eval(x, w, y_)\n",
    "    losses.append(loss)\n",
    "\n",
    "    if (i % 400 == 3):\n",
    "        print(f'Iter: {i:>3} Loss: {loss:8.8f}\\n w: {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BextVVMWu6TB"
   },
   "source": [
    "Let's visually asses our model. We can do this by using our estimates for $a,b,c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1728923531587,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "B7EqQsPk4Vxb",
    "outputId": "b8d6ff94-83c0-4653-87a1-cf810ac907cd"
   },
   "outputs": [],
   "source": [
    "w = w.reshape(-1)\n",
    "lin_fun2 = get_y_fun(w[1], w[2], w[0])\n",
    "\n",
    "print(-a/b, -c/b)\n",
    "print(\"Esimated to:\")\n",
    "print(-w[1]/w[2], -w[0]/w[2])\n",
    "\n",
    "training_set_accuracy = np.sum((h(x, w) > 1/2) == np.array(y))/n\n",
    "print(f'Accuracy on training data: {training_set_accuracy}')\n",
    "\n",
    "fig = px.line(y=losses, labels={'y':'loss'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1728923532868,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "odWHQD9Au6TE",
    "outputId": "4d94ffea-dcee-4125-e837-1e49c0c5a651"
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# TODO: Pass your estimates for a,b,c to the get_y_fun function #\n",
    "#################################################################\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n",
    "x_range = [np.min(X[:, 0]), np.max(X[:, 1])]\n",
    "fig.add_scatter(x=x_range, y=list(map(lin_fun, x_range)), name='ground truth border')\n",
    "fig.add_scatter(x=x_range, y=list(map(lin_fun2, x_range)), name='estimated border')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u43DFWVFu6TO"
   },
   "source": [
    "Let's now complicate the things a little bit and make our next problem nonlinear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1728923538010,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "qNCns_WIu6TS"
   },
   "outputs": [],
   "source": [
    "# Parameters of the ellipse\n",
    "s1 = 1.\n",
    "s2 = 2.\n",
    "r = 0.75\n",
    "m1 = 0.15\n",
    "m2 = 0.125\n",
    "\n",
    "# 0/1 mapping, checks whether we are inside the ellipse\n",
    "def circle_rule(x, y, noise=0.):\n",
    "    return 1 if s1 * (x - m1) ** 2 + s2 * (y - m2) ** 2 + noise < r ** 2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1728923539453,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "H91RdYcOu6Tb",
    "outputId": "a7b716d9-51ff-4407-d2f7-5f428959697a"
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "\n",
    "n = 500\n",
    "range_points = 1\n",
    "\n",
    "sigma = 0.1\n",
    "\n",
    "X = range_points * 2 * (np.random.rand(n, 2) - 0.5)\n",
    "\n",
    "y = [circle_rule(x, y, sigma * np.random.normal()) for x, y in X]\n",
    "\n",
    "print(X[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1keKZp-su6Tl"
   },
   "source": [
    "Let's plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1728923548470,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "_5qQnZLBu6Tr",
    "outputId": "bc53c770-84f2-481f-d343-2e9fa93bf0d3"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n",
    "\n",
    "xgrid = np.arange(np.min(X[:, 0]), np.max(X[:, 0]), 0.003)\n",
    "ygrid = np.arange(np.min(X[:, 1]), np.max(X[:, 1]), 0.003)\n",
    "contour =  go.Contour(\n",
    "        z=np.vectorize(circle_rule)(*np.meshgrid(xgrid, ygrid, indexing=\"ij\")),\n",
    "        x=xgrid,\n",
    "        y=ygrid\n",
    "    )\n",
    "fig.add_trace(contour)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMwKzVQZu6Tw"
   },
   "source": [
    "Now, let's train a logistic regression model to tackle this problem. Note that we now need a nonlinear decision boundary. You should obtain accuracy of at least 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kcnc848fu6Tx"
   },
   "source": [
    "Hint:\n",
    "<sub><sup><sub><sup><sub><sup>\n",
    "Use feature engineering.\n",
    "</sup></sub></sup></sub></sup></sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1728923553427,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "2Sc1CFWtUc38"
   },
   "outputs": [],
   "source": [
    "features = 5\n",
    "\n",
    "lr = 0.5 # step size\n",
    "treshold = 1/2\n",
    "n_epochs = 7000 # number of passes over the training data\n",
    "\n",
    "def ed(np_arr):\n",
    "    return np.expand_dims(np_arr, axis = 1)\n",
    "\n",
    "new_features = [np.ones(n), X[:,0]**2, X[:,1]**2]\n",
    "new_features = list(map(ed, new_features))\n",
    "new_features.append(X)\n",
    "\n",
    "x = np.hstack(new_features)\n",
    "w = np.array([0] * features).reshape(-1,1)\n",
    "y_ = np.array(y).reshape(n,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1728923560718,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "7lH94mTGr1Tz"
   },
   "outputs": [],
   "source": [
    "### Setup animation\n",
    "res = .02\n",
    "frames = 100\n",
    "\n",
    "xgrid = np.arange(np.min(X[:, 0]), np.max(X[:, 0]), res)\n",
    "ygrid = np.arange(np.min(X[:, 1]), np.max(X[:, 1]), res)\n",
    "\n",
    "xx, yy = np.meshgrid(xgrid, ygrid, indexing=\"ij\")\n",
    "X_plot = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "_X = np.concatenate([np.ones(len(xgrid)*len(ygrid)).reshape(-1,1), X_plot**2, X_plot], axis=1)\n",
    "\n",
    "all_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1993,
     "status": "ok",
     "timestamp": 1728923566150,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "cPINtZzou6T0",
    "outputId": "0455e1c3-44ab-4da2-85e5-e5a0e2395e5a"
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "# TODO: Implement logistic regression and compute its accuracy #\n",
    "################################################################\n",
    "def sigm(z):\n",
    "    return 1/(1+np.e**(-z))\n",
    "\n",
    "def h(x, w):\n",
    "    #print(sigm(x @ w)[:10])\n",
    "    return sigm(x @ w)\n",
    "\n",
    "def log_loss_eval(x, w_vec, y_vec):\n",
    "\n",
    "    #here boolean values automatically cast\n",
    "    arr = (y_vec * np.log(h(x, w_vec)) + (1 - y_vec) * np.log(1 - h(x, w_vec)))\n",
    "\n",
    "    #print(arr[:10])\n",
    "    return -1/n * np.sum(arr)\n",
    "\n",
    "log_loss_eval(x, w, y_)\n",
    "\n",
    "def predict(w, x=x):\n",
    "    return h(x, w) > treshold\n",
    "\n",
    "losses = [log_loss_eval(x, w, y_)]\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    if((i+1) % (n_epochs / frames) == 0):\n",
    "        preds = (h(_X, w) > treshold).astype(int).reshape(len(xgrid), len(ygrid))\n",
    "        all_preds.append(preds)\n",
    "\n",
    "    yhat = h(x, w)\n",
    "    dJdwj = (np.sum((yhat - y_) * x, axis = 0))\n",
    "\n",
    "    new_w = w - (1/n) * (lr * dJdwj).reshape(-1, 1)\n",
    "    w = new_w\n",
    "\n",
    "    loss = log_loss_eval(x, w, y_)\n",
    "    losses.append(loss)\n",
    "\n",
    "    if ((i+1) % (n_epochs/10) == 0):\n",
    "        print(f'Iter: {i:>3} Loss: {loss:8.8f}\\n w: {w}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1728923583447,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "GIk3jStYYQ9w",
    "outputId": "c41768e3-790f-4f81-eb67-5509ea7c67b9"
   },
   "outputs": [],
   "source": [
    "w = w.reshape(-1)\n",
    "\n",
    "training_set_accuracy = np.sum((h(x, w) > 1/2) == np.array(y))/n\n",
    "print(f'Accuracy on training data: {training_set_accuracy}')\n",
    "\n",
    "fig = px.line(y=losses, labels={'y':'loss'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nYLJvI4u6T7"
   },
   "source": [
    "Let's visually asses our model.\n",
    "\n",
    "Contrary to the previous scenario, converting our weights to parameters of the ground truth curve may not be straightforward. It's easier to just provide predictions for a set of points in $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1728923602937,
     "user": {
      "displayName": "Jakub Nowacki",
      "userId": "04628940980631792389"
     },
     "user_tz": -120
    },
    "id": "8vn13Nfuu6T9",
    "outputId": "f7435dc2-09fe-4094-91cd-f3e93918cd1c"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add initial contour plot for the first frame\n",
    "contour = go.Contour(\n",
    "    z=all_preds[0],\n",
    "    x=xgrid,\n",
    "    y=ygrid,\n",
    "    opacity=0.6,\n",
    "    colorscale=\"Blues\",\n",
    "    name=\"contour\",\n",
    ")\n",
    "\n",
    "scatter = go.Scatter(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(color=['green' if l == 0 else 'red' for l in y], size=10),\n",
    "    name=\"points\",\n",
    ")\n",
    "\n",
    "fig.add_trace(contour)\n",
    "fig.add_trace(scatter)\n",
    "\n",
    "# Create frames for the animation\n",
    "frames = []\n",
    "for i, preds in enumerate(all_preds):\n",
    "    contour = go.Contour(\n",
    "        z=preds,\n",
    "        x=xgrid,\n",
    "        y=ygrid,\n",
    "        opacity=0.6,\n",
    "        colorscale=\"Blues\",\n",
    "        name=\"contour\",\n",
    "    )\n",
    "\n",
    "    frame = go.Frame(data=[contour])\n",
    "    frames.append(frame)\n",
    "\n",
    "# Add the frames to the figure\n",
    "fig.frames = frames\n",
    "\n",
    "# Define the animation settings\n",
    "animation_settings = dict(\n",
    "    frame=dict(duration=100, redraw=True),\n",
    "    fromcurrent=True,\n",
    "    mode='immediate'\n",
    ")\n",
    "\n",
    "# Add play/pause buttons for the animation\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'showactive': False,\n",
    "        'buttons': [\n",
    "            {\n",
    "                'label': 'Play',\n",
    "                'method': 'animate',\n",
    "                'args': [None, animation_settings]\n",
    "            },\n",
    "            {\n",
    "                'label': 'Pause',\n",
    "                'method': 'animate',\n",
    "                'args': [[None], dict(frame=dict(duration=0, redraw=False), mode='immediate')]\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Show the animated contour plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1WAS-WJaw2XI-0zWy3SqD9wpb_-oUcsoc",
     "timestamp": 1728656607504
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
